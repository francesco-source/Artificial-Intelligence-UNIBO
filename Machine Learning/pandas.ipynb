{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "KFold # allows us to set a seed in our data and make it repeateble\n",
    "kf = KFold( n_splits = 6, shuffle=True,  random_state=42)\n",
    "reg = LinearRegression()\n",
    "X,y =...\n",
    "cv_result = cross_val_score(reg,X,y,cv=kf)# returns an arrayof cross validation scores. The default score is R^2\n",
    "print(cv_result)\n",
    "print(np.mean(cv_result),np.std(cv_result))#coumputing the statistics\n",
    "print(np.quantile(cv_result,[0.025,0.975]))#confidence level of 95% "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "Xtrain, ytrain, Xtest,ytest =...\n",
    "scores = []\n",
    "for alpha in [0.1,1,10,100,1000]:\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(Xtrain,ytrain)\n",
    "    y_pred = ridge.predict(Xtest)\n",
    "    scores.append(ridge.scores(Xtest,ytest))\n",
    "    #gets worst as alpha increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "scores = []\n",
    "for alpha in [0.1,1,10,100,1000]:\n",
    "    lasso = Lasso(alpha = alpha)\n",
    "    lasso.fit(Xtrain,ytrain)\n",
    "    y_pred = lasso.predict(Xtest)\n",
    "    lasso_coef = lasso.coef_\n",
    "    scores.append(lasso.scores(Xtest,ytest))\n",
    "    #get worse as alpha increases \n",
    "colonne_dataset = ...\n",
    "plt.bar(colonne_dataset, lasso_coef)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy and evaluation of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usually che class of interest is the positive one\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain,ytest = train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(Xtrain,ytrain)\n",
    "y_pred = knn.predict(Xtest)\n",
    "print(confusion_matrix(ytest,y_pred))\n",
    "print(classification_report(ytest,y_pred))\n",
    "# high precisin = low false positive rate\n",
    "# high precision = not many legitimate transactions are predicted to be fraudolent\n",
    "# high recall = low false negative rate\n",
    "# high recall = predicted most fraudolent transactions correctly\n",
    "# f1 score = armonic mean of precision and recall\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression and ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's used fro classification, produces a linear decision boundery\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3,random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Preciting probabilities\n",
    "y_pred_probs = logreg.predict_proba(Xtest)[:,1] #returns a 2d array for both classes. We coose se second colum\n",
    "#defoult treshold 0.5 \n",
    "# Roc curve \n",
    "from sklearn.metrics import roc_curve\n",
    "fpr,tpr,threshold = roc_curve(y_test,y_pred_probs)\n",
    "# evaluating the performance of ROC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(y_test,y_pred_probs))# area del sottografico\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use cross validation for tuning hyperparameters to avoid overfitting on the test set.\n",
    "#Grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "kf = KFold( n_splits=5,shuffle = True, random_state=42)\n",
    "param_grid = {\"alpha\":np.arange(0.0001,1,10),\"solver\":[\"sag\",\"lsqr\"]}\n",
    "ridge = Ridge()\n",
    "ridge_cv = GridSearchCV(ridge,param_grid,cv = kf)\n",
    "ridge_cv.fit(X_train,y_train)\n",
    "print(ridge_cv.best_params_,ridge_cv.best_score_)\n",
    "#RandomizeSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "kf = KFold( n_splits=5,shuffle = True, random_state=42)\n",
    "param_grid = {\"alpha\":np.arange(0.0001,1,10),\"solver\":[\"sag\",\"lsqr\"]}\n",
    "ridge = Ridge()\n",
    "ridge_cv = RandomizedSearchCV(ridge,param_grid,cv=kf,n_iter=2)#n_iter = number of iperpearameters to search. For example cross val =5 and \n",
    "# 2 n_iter performs 10 fits\n",
    "ridge_cv.fit(X_train,y_train)\n",
    "print(ridge_cv.best_params_,ridge_cv.best_score_)\n",
    "test_score = ridge_cv.score(X_test,y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initially we will build a regression model to predict some popularity\n",
    "import pandas as pd\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4 (tags/v3.9.4:1f2e308, Apr  6 2021, 13:40:21) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
