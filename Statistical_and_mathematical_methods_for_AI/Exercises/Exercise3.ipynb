{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient discent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x_R2):\n",
    "    return (x_R2[0]-3)**2+(x_R2[1]-1)**2\n",
    "def grad_f1(x_R2):\n",
    "    return np.array((2*(x_R2[0]-3),2*(x_R2[1]-1)))\n",
    "\n",
    "def f2(x_R2):\n",
    "    return 10*(x_R2[0]-1)**2+(x_R2[1]-2)**2\n",
    "def grad_f2(x_R2):\n",
    "    return np.array((20*(x_R2[0]-1),2*(x_R2[1]-2)))\n",
    "\n",
    "def f3(x_Rn):   \n",
    "    A=np.vander(np.linspace(0,1,len(x_Rn)),len(x_Rn))\n",
    "    return 0.5*np.linalg.norm(A@x_Rn-A@np.ones(len(x_Rn),).T,2)**2\n",
    "def grad_f3(x_Rn):\n",
    "    A=np.vander(np.linspace(0,1,len(x_Rn),dtype=int),len(x_Rn))\n",
    "    grad=[]\n",
    "    vector=np.array(A@x_Rn-A@np.ones(len(x_Rn),).T)\n",
    "    for i in range(len(x_Rn)):\n",
    "        grad.append(vector[i])\n",
    "    return np.array(grad)\n",
    "\n",
    "def f4(x_Rn):\n",
    "    A=np.vander(np.linspace(0,1,len(x_Rn)),len(x_Rn))\n",
    "    #lambda must be from zero to one\n",
    "    lambda_=0.5\n",
    "    return 0.5*(np.linalg.norm(A@x_Rn-A@np.ones(len(x_Rn),).T,2)+lambda_*np.linalg.norm(x_Rn,2))\n",
    "def grad_f4(x_Rn):\n",
    "    A=np.vander(np.linspace(0,1,len(x_Rn)),len(x_Rn))\n",
    "    lambda_=0.5\n",
    "    grad=np.zeros((len(x_Rn)))\n",
    "    vector1=np.array(A@x_Rn-A@np.ones(len(x_Rn),).T)\n",
    "    for i in range(len(x_Rn)):\n",
    "        grad[i]=lambda_*np.array(x_Rn)[i]+vector1[i]\n",
    "    return np.array(grad)\n",
    "\n",
    "def f5(x):\n",
    "    return np.array((x**4+x**3-2*x**2-2*x)).reshape(1,1)\n",
    "def grad_f5(x):\n",
    "    return np.array((4*x**3+3*x**2-4*x-2)).reshape(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking(f, grad_f, x):\n",
    "    \"\"\"\n",
    "    This function is a simple implementation of the backtracking algorithm for\n",
    "    the GD (Gradient Descent) method.\n",
    "    \n",
    "    f: function. The function that we want to optimize.\n",
    "    grad_f: function. The gradient of f(x).\n",
    "    x: ndarray. The actual iterate x_k.\n",
    "    \"\"\"\n",
    "    alpha = 1\n",
    "    c = 0.8\n",
    "    tau = 0.25\n",
    "    \n",
    "    while f(x - alpha * grad_f(x)) > f(x) - c * alpha * np.linalg.norm(grad_f(x),2)**2 :\n",
    "        alpha = tau * alpha\n",
    "        \n",
    "        if alpha < 1e-3:\n",
    "            break\n",
    "    return alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(f,grad_f,x0=(2.8,0.1),tolf=10e-6,tolx=10e-6,kmax=1000,back=True):\n",
    "    #As output x as stationary point\n",
    "    #f<-val a vector containing the values of f during the iterations\n",
    "    #err_vall a vector containing the values of || grad of f(x,k)||\n",
    "    alpha=0.01\n",
    "    #initialization:\n",
    "    f_val=np.zeros((kmax+1,))\n",
    "    err_val=np.zeros((kmax+1,))\n",
    "    k=0\n",
    "    try:\n",
    "        x_k=np.array(x0)\n",
    "        x_km1=np.zeros((len(x0),))\n",
    "    except:\n",
    "        x_k=np.array(x0).reshape(1,1)\n",
    "        x_km1=np.array(0).reshape(1,1)\n",
    "    cond1=True\n",
    "    cond2=True                                         \n",
    "    while(cond1 and cond2 and k<kmax):\n",
    "        x_km1=x_k\n",
    "        if back==True:\n",
    "             alpha=backtracking(f,grad_f,x_k)\n",
    "        else:\n",
    "            alpha=alpha\n",
    "        x_k=x_k-alpha*grad_f(x_k)  \n",
    "        f_val[k]=f(x_k)\n",
    "        k+=1\n",
    "        err_val[k]=np.linalg.norm(grad_f(x_k),2)\n",
    "        cond1=np.linalg.norm(grad_f(x_k),2)>tolf*np.linalg.norm(grad_f(x0),2) \n",
    "        cond2=np.linalg.norm(x_k-x_km1,2)>tolx*np.linalg.norm(x_km1,2)    \n",
    "    print(k)\n",
    "    return x_k,f_val,err_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punto 1\n",
    "Funzione 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335\n",
      "[2.9988499  0.99896491]\n",
      "66\n",
      "[2.99985122 0.9998661 ]\n"
     ]
    }
   ],
   "source": [
    "x_k,_1,_2=GD(f1,grad_f1,(2,0.1),back=False)\n",
    "print(x_k)\n",
    "x_k,_1,_2=GD(f1,grad_f1,(2,0.1),back=True)\n",
    "print(x_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338\n",
      "[1.         1.99891754]\n",
      "71\n",
      "[1.        1.9998444]\n"
     ]
    }
   ],
   "source": [
    "x_k,_1,_2=GD(f2,grad_f2,(0.5,1),back=False)\n",
    "print(x_k)\n",
    "x_k,_1,_2=GD(f2,grad_f2,(0.5,1),back=True)\n",
    "print(x_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[-832818.86598345 -832819.86598345 -832818.86598345 -832818.86598345\n",
      " 1300493.59467773]\n",
      "1000\n",
      "[ 0.25759264 -0.74240736  0.25759264  0.25759264  2.53819744]\n"
     ]
    }
   ],
   "source": [
    "x_k,_1,_2=GD(f3,grad_f3,(1,0,1,1,1),back=False)\n",
    "print(x_k)\n",
    "x_k,_1,_2=GD(f3,grad_f3,(1,0,1,1,1),back=True)\n",
    "print(x_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[-619.8004997  -580.84519481 -424.99515488  -35.30486235  753.18735477]\n",
      "1000\n",
      "[ 0.36715959 -0.2130943   0.54713641  0.91916995  1.6515605 ]\n"
     ]
    }
   ],
   "source": [
    "x_k,_1,_2=GD(f4,grad_f4,(1,0,1,1,1),back=False) \n",
    "print(x_k)\n",
    "x_k,_1,_2=GD(f4,grad_f4,(1,0,1,1,1),back=True) \n",
    "print(x_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "[[0.9222868]]\n",
      "53\n",
      "[[0.92225903]]\n"
     ]
    }
   ],
   "source": [
    "x_k,_1,_2=GD(f5,grad_f5,(2),back=False)\n",
    "print(x_k)\n",
    "x_k,_1,_2=GD(f5,grad_f5,(2),back=True)\n",
    "print(x_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
